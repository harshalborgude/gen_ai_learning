{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with langchain And OpenAI\n",
    "- OpenAI\n",
    "- Prompt Template\n",
    "- Chains\n",
    "- Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith tracking enabling\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000022A8CE74E30> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022A8CE77DD0> root_client=<openai.OpenAI object at 0x0000022A8A173A40> root_async_client=<openai.AsyncOpenAI object at 0x0000022A8CE75040> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "## It will take api key from environment vars \n",
    "# llm = ChatOpenAI(api_key=\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence algorithms designed to produce new data that is similar to existing data. Unlike traditional AI, which is typically used for tasks such as classification, prediction, and optimization, generative AI creates new content. This can include generating text, images, audio, video, and other forms of data.\\n\\nKey techniques and models in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates fake data, while the discriminator tries to distinguish between real and fake data. Over time, the generator gets better at creating data that can fool the discriminator.\\n\\n2. **Variational Autoencoders (VAEs)**: VAEs are used to generate new data by learning a latent space representation of the input data. They work by encoding the input into a probabilistic latent space and then decoding from this space to generate new data.\\n\\n3. **Transformers**: These are particularly effective for generating text and have been used in models like GPT (Generative Pre-trained Transformer). Transformers use self-attention mechanisms to process and generate sequences of data, making them highly effective for natural language processing tasks.\\n\\n4. **Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs)**: These are used for generating sequences of data, such as text, music, or time-series data. They can capture temporal dependencies in sequential data.\\n\\nApplications of generative AI include:\\n\\n- **Text Generation**: Examples include chatbots, automated news articles, and creative writing.\\n- **Image Generation**: This includes creating realistic images, enhancing image quality, and generating art.\\n- **Music and Audio Generation**: Composing new music or generating realistic human speech.\\n- **Data Augmentation**: Creating synthetic data to augment training datasets for machine learning models.\\n- **Drug Discovery**: Generating new molecular structures for potential pharmaceuticals.\\n\\nGenerative AI has transformative potential across many fields but also raises ethical considerations, such as the creation of deepfakes, intellectual property issues, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 436, 'prompt_tokens': 12, 'total_tokens': 448, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None} id='run-c5c363d8-1e3e-40f3-8b48-fa2a4bb54158-0' usage_metadata={'input_tokens': 12, 'output_tokens': 436, 'total_tokens': 448}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM \n",
    "\n",
    "# result = llm.invoke(\"What is generative AI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence algorithms designed to produce new data that is similar to existing data. Unlike traditional AI, which is typically used for tasks such as classification, prediction, and optimization, generative AI creates new content. This can include generating text, images, audio, video, and other forms of data.\\n\\nKey techniques and models in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates fake data, while the discriminator tries to distinguish between real and fake data. Over time, the generator gets better at creating data that can fool the discriminator.\\n\\n2. **Variational Autoencoders (VAEs)**: VAEs are used to generate new data by learning a latent space representation of the input data. They work by encoding the input into a probabilistic latent space and then decoding from this space to generate new data.\\n\\n3. **Transformers**: These are particularly effective for generating text and have been used in models like GPT (Generative Pre-trained Transformer). Transformers use self-attention mechanisms to process and generate sequences of data, making them highly effective for natural language processing tasks.\\n\\n4. **Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs)**: These are used for generating sequences of data, such as text, music, or time-series data. They can capture temporal dependencies in sequential data.\\n\\nApplications of generative AI include:\\n\\n- **Text Generation**: Examples include chatbots, automated news articles, and creative writing.\\n- **Image Generation**: This includes creating realistic images, enhancing image quality, and generating art.\\n- **Music and Audio Generation**: Composing new music or generating realistic human speech.\\n- **Data Augmentation**: Creating synthetic data to augment training datasets for machine learning models.\\n- **Drug Discovery**: Generating new molecular structures for potential pharmaceuticals.\\n\\nGenerative AI has transformative potential across many fields but also raises ethical considerations, such as the creation of deepfakes, intellectual property issues, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 436, 'prompt_tokens': 12, 'total_tokens': 448, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None} id='run-c5c363d8-1e3e-40f3-8b48-fa2a4bb54158-0' usage_metadata={'input_tokens': 12, 'output_tokens': 436, 'total_tokens': 448}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a category of artificial intelligence algorithms designed to produce new data that is similar to existing data. Unlike traditional AI, which is typically used for tasks such as classification, prediction, and optimization, generative AI creates new content. This can include generating text, images, audio, video, and other forms of data.\n",
      "\n",
      "Key techniques and models in generative AI include:\n",
      "\n",
      "1. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates fake data, while the discriminator tries to distinguish between real and fake data. Over time, the generator gets better at creating data that can fool the discriminator.\n",
      "\n",
      "2. **Variational Autoencoders (VAEs)**: VAEs are used to generate new data by learning a latent space representation of the input data. They work by encoding the input into a probabilistic latent space and then decoding from this space to generate new data.\n",
      "\n",
      "3. **Transformers**: These are particularly effective for generating text and have been used in models like GPT (Generative Pre-trained Transformer). Transformers use self-attention mechanisms to process and generate sequences of data, making them highly effective for natural language processing tasks.\n",
      "\n",
      "4. **Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs)**: These are used for generating sequences of data, such as text, music, or time-series data. They can capture temporal dependencies in sequential data.\n",
      "\n",
      "Applications of generative AI include:\n",
      "\n",
      "- **Text Generation**: Examples include chatbots, automated news articles, and creative writing.\n",
      "- **Image Generation**: This includes creating realistic images, enhancing image quality, and generating art.\n",
      "- **Music and Audio Generation**: Composing new music or generating realistic human speech.\n",
      "- **Data Augmentation**: Creating synthetic data to augment training datasets for machine learning models.\n",
      "- **Drug Discovery**: Generating new molecular structures for potential pharmaceuticals.\n",
      "\n",
      "Generative AI has transformative potential across many fields but also raises ethical considerations, such as the creation of deepfakes, intellectual property issues, and the potential for misuse.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPrompt Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answer based on the question')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatPrompt Template \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain\n",
    "\n",
    "## Creating a chain using pipe\n",
    "## Here it will go through prompt and then through LLM , and then finally it will give response \n",
    "\n",
    "chain = prompt|llm\n",
    "# response = chain.invoke({\"input\":\"can you tell me about langsmith ?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! As of my last update in October 2023, there isn\\'t a widely recognized tool, framework, or concept named \"Langsmith\" in the AI or software engineering domains. It\\'s possible that \"Langsmith\" could refer to a newly introduced tool, a proprietary system, or a concept not widely documented or recognized in mainstream channels.\\n\\nHowever, if we break down the term:\\n\\n- \"Lang\" typically stands for \"language,\" which could imply something related to programming languages, natural languages, or language processing.\\n- \"Smith\" suggests craftsmanship or expertise, as in a blacksmith or wordsmith, implying a high level of skill or specialization.\\n\\nGiven this, \"Langsmith\" could hypothetically be a tool, platform, or role that specializes in the creation, manipulation, or optimization of languages, whether programming languages or natural languages.\\n\\nIf you have more context or specific details about \"Langsmith,\" please provide them, and I can offer more tailored information or insights. Otherwise, it would be wise to check recent sources or documentation to see if \"Langsmith\" has been introduced or popularized after my last update.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 33, 'total_tokens': 258, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None} id='run-71e8282b-6b21-49bf-8a90-8806fb3942f3-0' usage_metadata={'input_tokens': 33, 'output_tokens': 225, 'total_tokens': 258}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! As of my last update in October 2023, there isn't a widely recognized tool, framework, or concept named \"Langsmith\" in the AI or software engineering domains. It's possible that \"Langsmith\" could refer to a newly introduced tool, a proprietary system, or a concept not widely documented or recognized in mainstream channels.\n",
      "\n",
      "However, if we break down the term:\n",
      "\n",
      "- \"Lang\" typically stands for \"language,\" which could imply something related to programming languages, natural languages, or language processing.\n",
      "- \"Smith\" suggests craftsmanship or expertise, as in a blacksmith or wordsmith, implying a high level of skill or specialization.\n",
      "\n",
      "Given this, \"Langsmith\" could hypothetically be a tool, platform, or role that specializes in the creation, manipulation, or optimization of languages, whether programming languages or natural languages.\n",
      "\n",
      "If you have more context or specific details about \"Langsmith,\" please provide them, and I can offer more tailored information or insights. Otherwise, it would be wise to check recent sources or documentation to see if \"Langsmith\" has been introduced or popularized after my last update.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroutput Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here creating a chain\n",
    "## First it will invoke prompt , after that it invoke llm model and later it will invoke output_parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "# response = chain.invoke({\"input\":\"can you tell me about langsmith ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! LangSmith is a tool designed to help developers build, monitor, and evaluate applications that utilize large language models (LLMs). It is particularly valuable given the increasing complexity and importance of LLMs in modern applications. Here are some key features and aspects of LangSmith:\n",
      "\n",
      "1. **Development**: LangSmith provides a suite of tools and frameworks that simplify the integration of large language models into applications. This includes APIs, SDKs, and libraries that facilitate the seamless incorporation of LLMs into various software environments.\n",
      "\n",
      "2. **Monitoring**: One of the critical aspects of working with LLMs is ensuring they perform as expected in real-world scenarios. LangSmith offers robust monitoring capabilities to track the performance of these models. This includes real-time analytics, logging, and alerting systems to notify developers of any anomalies or performance issues.\n",
      "\n",
      "3. **Evaluation**: Evaluating the performance and accuracy of LLMs is essential for maintaining high-quality applications. LangSmith provides tools for benchmarking and testing models, allowing developers to assess their performance against various metrics and datasets. This can include things like accuracy, response time, relevance, and more.\n",
      "\n",
      "4. **Customization**: Understanding that different applications have unique requirements, LangSmith allows for extensive customization of LLMs to better fit the specific needs of a given project. This can involve fine-tuning models, adjusting parameters, and implementing custom algorithms.\n",
      "\n",
      "5. **Scalability**: LangSmith is designed to handle the demands of large-scale applications, ensuring that performance remains consistent even as the user base grows. This includes support for distributed computing and efficient resource management.\n",
      "\n",
      "6. **Security and Compliance**: Given the sensitivity of data often handled by LLMs, LangSmith places a strong emphasis on security and compliance. This includes data encryption, access controls, and adherence to industry standards and regulations.\n",
      "\n",
      "Overall, LangSmith provides a comprehensive platform for managing the lifecycle of applications that leverage large language models, from development and deployment to monitoring and evaluation. This makes it easier for developers to harness the power of LLMs while maintaining high standards of performance and reliability.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
